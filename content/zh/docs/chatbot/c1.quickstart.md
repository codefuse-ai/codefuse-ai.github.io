---
title: å¿«é€Ÿå¼€å§‹
slug: å¿«é€Ÿå¼€å§‹
description: ä»‹ç»ä¸»è¦åŠŸèƒ½
url: "docs/å¿«é€Ÿå¼€å§‹"
aliases:
- "/docs/å¿«é€Ÿå¼€å§‹"
- "/docs/quickstart-zh"
---

<p align="left">
    <a>ä¸­æ–‡</a>&nbsp ï½œ &nbsp<a href="/docs/quickstart">English&nbsp </a>
</p>


## ğŸš€ å¿«é€Ÿä½¿ç”¨

å¦‚éœ€ä½¿ç”¨ç§æœ‰åŒ–æ¨¡å‹éƒ¨ç½²ï¼Œè¯·è‡ªè¡Œå®‰è£… nvidia é©±åŠ¨ç¨‹åºï¼Œæœ¬é¡¹ç›®å·²åœ¨ Python 3.9.18ï¼ŒCUDA 11.7 ç¯å¢ƒä¸‹ï¼ŒWindowsã€X86 æ¶æ„çš„ macOS ç³»ç»Ÿä¸­å®Œæˆæµ‹è¯•ã€‚

Dockerå®‰è£…ã€ç§æœ‰åŒ–LLMæ¥å…¥åŠç›¸å…³å¯åŠ¨é—®é¢˜è§ï¼š[å¿«é€Ÿä½¿ç”¨æ˜ç»†](/docs/start-detail-zh)

### python ç¯å¢ƒå‡†å¤‡

- æ¨èé‡‡ç”¨ conda å¯¹ python ç¯å¢ƒè¿›è¡Œç®¡ç†ï¼ˆå¯é€‰ï¼‰
```bash
# å‡†å¤‡ conda ç¯å¢ƒ
conda create --name devopsgpt python=3.9
conda activate devopsgpt
```

- å®‰è£…ç›¸å…³ä¾èµ–
```bash
cd codefuse-chatbot
pip install -r requirements.txt
```

### åŸºç¡€é…ç½®

```bash
# ä¿®æ”¹æœåŠ¡å¯åŠ¨çš„åŸºç¡€é…ç½®
cd configs
cp model_config.py.example model_config.py
cp server_config.py.example server_config.py

# model_config#11~12 è‹¥éœ€è¦ä½¿ç”¨openaiæ¥å£ï¼Œopenaiæ¥å£key
os.environ["OPENAI_API_KEY"] = "sk-xxx"
# å¯è‡ªè¡Œæ›¿æ¢è‡ªå·±éœ€è¦çš„api_base_url
os.environ["API_BASE_URL"] = "https://api.openai.com/v1"

# vi model_config#LLM_MODEL ä½ éœ€è¦é€‰æ‹©çš„è¯­è¨€æ¨¡å‹
LLM_MODEL = "gpt-3.5-turbo"
LLM_MODELs = ["gpt-3.5-turbo"]

# vi model_config#EMBEDDING_MODEL ä½ éœ€è¦é€‰æ‹©çš„ç§æœ‰åŒ–å‘é‡æ¨¡å‹
EMBEDDING_ENGINE = 'model'
EMBEDDING_MODEL = "text2vec-base"

# å‘é‡æ¨¡å‹æ¥å…¥ç¤ºä¾‹ï¼Œä¿®æ”¹ model_config#embedding_model_dict
# è‹¥æ¨¡å‹åœ°å€ä¸ºï¼š
model_dir: ~/codefuse-chatbot/embedding_models/shibing624/text2vec-base-chinese
# é…ç½®å¦‚ä¸‹
"text2vec-base": "shibing624/text2vec-base-chinese"

# vi server_config#8~14, æ¨èé‡‡ç”¨å®¹å™¨å¯åŠ¨æœåŠ¡ï¼Œé¿å…ä½¿ç”¨codeInterpreteråŠŸèƒ½æ—¶å®‰è£…å…¶å®ƒä¾èµ–å¯¼è‡´ç¯å¢ƒå†²çª
DOCKER_SERVICE = True
# æ˜¯å¦é‡‡ç”¨å®¹å™¨æ²™ç®±
SANDBOX_DO_REMOTE = True
```

### å¯åŠ¨æœåŠ¡

é»˜è®¤åªå¯åŠ¨webuiç›¸å…³æœåŠ¡ï¼Œæœªå¯åŠ¨fastchatï¼ˆå¯é€‰ï¼‰ã€‚
```bash
# è‹¥éœ€è¦æ”¯æ’‘codellama-34b-int4æ¨¡å‹ï¼Œéœ€è¦ç»™fastchatæ‰“ä¸€ä¸ªè¡¥ä¸
# cp examples/gptq.py ~/site-packages/fastchat/modules/gptq.py
# examples/llm_api.py#258 ä¿®æ”¹ä¸º kwargs={"gptq_wbits": 4},

# start llm-serviceï¼ˆå¯é€‰ï¼‰
python examples/llm_api.py
```
æ›´å¤šLLMæ¥å…¥æ–¹æ³•è§[è¯¦æƒ…...](/docs/fastchat-zh)
<br>

```bash
# å®Œæˆserver_config.pyé…ç½®åï¼Œå¯ä¸€é”®å¯åŠ¨
cd examples
python start.py
```
