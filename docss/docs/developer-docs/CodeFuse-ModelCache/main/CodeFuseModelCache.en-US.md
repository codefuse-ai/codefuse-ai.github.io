---
nav:
  title: Docs
  order: -1
  second:
    title: Developer-Docs
    order: -1
store:
  title: CodeFuse-ModelCache
  version: main
group:
  title: ðŸŒ± CodeFuse-ModelCache
  index: true
  order: -1
title: CodeFuse-ModelCache
order: -1
toc: content
github: https://github.com/codefuse-ai/CodeFuse-ModelCache
---

## Contents

- [news](#news)
- [Introduction](#Introduction)
- [Modules](#Modules)
- [Acknowledgements](#Acknowledgements)
- [Contributing](#Contributing)

## news

- ðŸ”¥ðŸ”¥[2023.12.10] we integrate LLM embedding frameworks such as 'llmEmb', 'ONNX', 'PaddleNLP', 'FastText', alone with the image embedding framework 'timm', to bolster embedding functionality.
- ðŸ”¥ðŸ”¥[2023.11.20] codefuse-ModelCache has integrated local storage, such as sqlite and faiss, providing users with the convenience of quickly initiating tests.
- [2023.08.26] codefuse-ModelCache...

## Introduction

Codefuse-ModelCache is a semantic cache for large language models (LLMs). By caching pre-generated model results, it reduces response time for similar requests and improves user experience. <br />This project aims to optimize services by introducing a caching mechanism. It helps businesses and research institutions reduce the cost of inference deployment, improve model performance and efficiency, and provide scalable services for large models. Through open-source, we aim to share and exchange technologies related to large model semantic cache.

## modules

![modelcache modules](https://mdn.alipayobjects.com/huamei_bvbxju/afts/img/A*Z-6cSr6udKAAAAAAAAAAAAAADlHYAQ/original)

## Acknowledgements

This project has referenced the following open-source projects. We would like to express our gratitude to the projects and their developers for their contributions and research.<br />[GPTCache](https://github.com/zilliztech/GPTCache)

## Contributing

ModelCache is a captivating and invaluable project, whether you are an experienced developer or a novice just starting out, your contributions to this project are warmly welcomed. Your involvement in this project, be it through raising issues, providing suggestions, writing code, or documenting and creating examples, will enhance the project's quality and make a significant contribution to the open-source community.
