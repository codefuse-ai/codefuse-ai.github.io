---
nav:
  title: Docs
  order: -1
  second:
    title: å¼€å‘è€…æ–‡æ¡£
    order: -1
store:
  title: CodeFuse-DevOps-Eval
  version: master
group:
  title: ğŸŒ± CodeFuse-DevOps-Eval
  order: -1
title: Data
order: -1
toc: content
---

## â¬ Data

#### Download

- Method 1: Download the zip file (you can also simply open the following link with the browser):

  ```
  wget https://huggingface.co/datasets/codefuse-admin/devopseval-exam/resolve/main/devopseval-exam.zip
  ```

  then unzip it and you may load the data with pandas:

  ```
  import os
  import pandas as pd

  File_Dir="devopseval-exam"
  test_df=pd.read_csv(os.path.join(File_Dir,"test","UnitTesting.csv"))
  ```

- Method 2: Directly load the dataset using [Hugging Face datasets](https://huggingface.co/datasets/codefuse-admin/devopseval-exam):

  ````python
  from datasets import load_dataset
  dataset=load_dataset(r"DevOps-Eval/devopseval-exam",name="UnitTesting")

  print(dataset['val'][0])
  # {"id": 1, "question": "å•å…ƒæµ‹è¯•åº”è¯¥è¦†ç›–ä»¥ä¸‹å“ªäº›æ–¹é¢ï¼Ÿ", "A": "æ­£å¸¸è·¯å¾„", "B": "å¼‚å¸¸è·¯å¾„", "C": "è¾¹ç•Œå€¼æ¡ä»¶"ï¼Œ"D": æ‰€æœ‰ä»¥ä¸Šï¼Œ"answer": "D", "explanation": ""}  ```

  ````

- Method 3: Use [modelscope](https://modelscope.cn/datasets/codefuse-ai/devopseval-exam/files) download all datasã€‚Examplesï¼š
  ````python
  from modelscope.msdatasets import MsDataset
  MsDataset.clone_meta(dataset_work_dir='./xxx', dataset_id='codefuse-ai/devopseval-exam')```
  ````

#### ğŸ‘€ Notes

To facilitate usage, we have organized the category name handlers and English/Chinese names corresponding to 55 subcategories. Please refer to [category_mapping.json](./categroy_mapping) for details. The format is:

```
{
  "UnitTesting.csv": [
    "unit testing",
    "å•å…ƒæµ‹è¯•",
    {"dev": 5, "test": 32}
    "TEST"
  ],
  ...
  "file_name":[
  "English Name",
  "Chinese Name",
  "Sample Number",
  "Supercatagory Label(PLAN,CODE,BUILD,TEST,RELEASE,DEPOLY,OPERATE,MONITOR choose 1 out of 8)"
  ]
}
```

Each subcategory consists of two splits: dev and test. The dev set per subcategory consists of five exemplars with explanations for few-shot evaluation. And the test set is for model evaluation. Labels on the test split are also released.

Below is a dev example from 'version control':

```
id: 4
question: å¦‚ä½•æ‰¾åˆ°Gitç‰¹å®šæäº¤ä¸­å·²æ›´æ”¹çš„æ–‡ä»¶åˆ—è¡¨ï¼Ÿ
A: ä½¿ç”¨å‘½ä»¤ `git diff --name-only SHA`
B: ä½¿ç”¨å‘½ä»¤ `git log --name-only SHA`
C: ä½¿ç”¨å‘½ä»¤ `git commit --name-only SHA`
D: ä½¿ç”¨å‘½ä»¤ `git clone --name-only SHA`
answer: A
explanation:
åˆ†æåŸå› ï¼š
git diff --name-only SHAå‘½ä»¤ä¼šæ˜¾ç¤ºä¸SHAå‚æ•°å¯¹åº”çš„æäº¤ä¸­å·²ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨ã€‚å‚æ•°--name-onlyè®©å‘½ä»¤åªè¾“å‡ºæ–‡ä»¶åï¼Œè€Œå¿½ç•¥å…¶ä»–ä¿¡æ¯ã€‚å…¶å®ƒé€‰é¡¹ä¸­çš„å‘½ä»¤å¹¶ä¸èƒ½å®ç°æ­¤åŠŸèƒ½ã€‚
```

#### ğŸ”¥ AIOps Sample Example

ğŸ‘€ ğŸ‘€ Taking **log parsing** and **time series anomaly detection** as examples, here is a brief showcase of the AIOps samples:

LogParsing

```
id: 0
question:
Here are some running logs
 0 04:21:15,429 WARN Cannot open channel to 2 at election address /10.10.34.12:3888
 1 19:18:56,377 WARN ******* GOODBYE /10.10.34.11:52703 ********
 2 19:13:46,128 WARN ******* GOODBYE /10.10.34.11:52308 ********
 3 19:16:26,268 WARN ******* GOODBYE /10.10.34.11:52502 ********
 4 09:11:16,012 WARN Cannot open channel to 3 at election address /10.10.34.13:3888
 5 16:37:13,837 WARN Cannot open channel to 2 at election address /10.10.34.12:3888
 6 09:09:16,008 WARN Cannot open channel to 3 at election address /10.10.34.13:3888
 7 15:27:03,681 WARN Cannot open channel to 3 at election address /10.10.34.13:3888
The first three parts of the log are index, timestamp, and log level. Without considering these three parts, Here we assume that the variables in the logs are represented as '<*>', separated by spaces between tokens. What is the specific log template for the above logs?
A: Notification time out: <*> å’Œ Connection broken for id <*>, my id = <*>, error =
B: Send worker leaving thread å’Œ Connection broken for id <*>, my id = <*>, error =
C: Received connection request /<*>:<*> å’Œ Interrupting SendWorker
D: Cannot open channel to <*> at election address /<*>:<*> å’Œ ******* GOODBYE /<*>:<*> ********
answer: D
explanation: The log includes the fixed template fragments "Cannot open channel to <> at election address /<>:<>" and "****** GOODBYE /<>:<> ********," both of which appear in option D. Meanwhile, the template fragments in the other options do not match the content in the log. Therefore, option D is the most consistent with the log template.
```

TimeSeriesAnomalyDetection

```
id: 0
question:
Analyze the following time series
[50,62,74,84,92,97,99,98,94,87,77,65,265,40,28,17,8,3,0,0,4,10,20,31,43,56,68,79,89,95,99,99,96,91,82,71,59,46,34,22,12,5,1,0,2,7,15,25,37,49]
Please identify the indices of obvious outlier points. Outlier points generally refer to points that significantly deviate from the overall trend of the data.
A: 46
B: 0
C: 37
D: 12
answer: D
explanation: According to the analysis, the value 265 in the given time series at 12 o'clock is significantly larger than the surrounding data, indicating a sudden increase phenomenon. Therefore, selecting option D is correct.
```

#### ğŸ”§ ToolLearning Sample Example

ğŸ‘€ ğŸ‘€The data format of ToolLearning samples is compatible with OpenAI's Function Calling.

Please refer to [tool_learning_info.md](/docs/developer-docs/CodeFuse-DevOps-Eval/master/tool_learning_info_zh) for details.
Tool Learning Data Evalution see [tool_learning_evalution.md](/docs/developer-docs/CodeFuse-DevOps-Eval/master/tool_learning_evalution)ã€‚
<br>
