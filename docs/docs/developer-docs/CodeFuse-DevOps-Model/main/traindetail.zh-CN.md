---
store:
  title: CodeFuse-DevOps-Model
  version: main
group:
  title: 🌱 CodeFuse-DevOps-Model
  order: -1
title: 训练解析
order: 0
toc: content
---

## 训练流程

根据查阅文献可知，大部分领域模型都是在对话模型的基础上，通过 SFT 微调来进行知识注入。而 SFT 微调所需要 QA 预料基本都来自于 ChatGPT 生成。然而，该方案可能存在 QA 语料无法完全覆盖领域知识的情况。
因此，DevOps-Model 采用的是预训练加训 + SFT 微调的方案，如图 2.1 所示。我们认为针对领域大模型，预训练的加训是必要的，因为其可以将领域内的一些知识在预训练阶段注入到大模型，如果这些知识在通用大模型预训练时没有出现过，那会让大模型学习到新的知识；如果出现过，就可以让大模型进一步加深印象。第二步则是大模型对齐，目的是让大模型可以根据问题来回答最合适的内容。

![](https://mdn.alipayobjects.com/huamei_bvbxju/afts/img/A*66DWSbAXqRAAAAAAAAAAAAAADlHYAQ/original)

## 训练数据

### 数据收集

模型的定位是中文 DevOps 领域大模型，因此收集与中文 DevOps 相关的预训练数据和 QA 数据。

- 预训练数据主要来自互联网技术博客、技术文档、技术书籍等，最终收集到了 50G+ 的预训练语料数据；
- 针对 QA 数据，我们的目的是想让模型不但对齐到通用的问答能力，而且针对 DevOps 领域也可以学会如何更好的回答问题，因此不但收集了通用领域的单轮和多轮对话数据，还针对 DevOps 领域，通过爬取和 ChatGPT 生成的方式产出了属于 DevOps 领域的问答数据。最终我们精心筛选了约 200K 的 QA 数据进行 SFT 微调训练，具体数据量如下表所示。

| 数据类型       | 数据量级 |
| -------------- | -------- |
| 通用单轮 QA    | 50K      |
| 通用多轮 QA    | 20K      |
| DevOps 领域 QA | 130K     |

### 数据筛选

![](https://mdn.alipayobjects.com/huamei_bvbxju/afts/img/A*jKlFTp3GWg8AAAAAAAAAAAAADlHYAQ/original)

由于预训练数据大部分是从互联网上收集的数据，质量会参差不齐，而大模型训练中数据是最重要的一环，我们建立了如上图所示的清洗 Pipeline，来针对收集到的数据进行质量的全面过滤。

1. 首先，由专家经验和人工筛选，总结出来了一批文档级别的 Heuristic 过滤规则，这一步主要用来过滤掉那些质量非常差的文档；
2. 然后，即便是一篇质量稍差的文章中，也有可能还是含有一些有价值的领域知识，我们也需要尽可能的进行收集。此处，我们对文章进行段落拆分，将文章拆分成一个个段落；
3. 然后，我们将拆分后的段落会再次通过步骤 1 进行过滤，便得到了一批经过规则过滤后的段落；
4. 然后，我们摘取了其中 1000 个段落，由经验丰富的专业开发人员来进行打标，获得高质量的打标数据；
5. 最后，我们根据打标后的结果来训练了一个打分模型来针对段落进行质量的打分，段落的向量模型选用了预训练好的中文版本的 Sentence-Bert，打分算法选用了逻辑回归，为了避免打分模型的误差，会再通过帕累托分布来根据段落的质量打分进行采样来决定要不要过滤这个段落。
   经过这个 Pipeline 后，我们最终沉淀下 15G 左右的数据来进行大模型的预训练加训。
