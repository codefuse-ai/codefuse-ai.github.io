<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CodeFuse-AI</title>
    <link>/</link>
    <description>Recent content on CodeFuse-AI</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Acknowledgements</title>
      <link>/contribution/acknowledgements/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/contribution/acknowledgements/</guid>
      <description>The documentation homepage of CodeFuse-ai is built on docura&#xA;The ChatBot project is based on langchain-chatchat and codebox-api.&#xA;&amp;hellip;&amp;hellip;&#xA;Deep gratitude is extended for their open-source contributions!</description>
    </item>
    <item>
      <title>Agent Flow</title>
      <link>/coagent/agent-flow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/agent-flow/</guid>
      <description>Introduction to Core Connectors To facilitate everyone&amp;rsquo;s understanding of the entire CoAgent link, we use a Flow format to detail how to build through configuration settings.&#xA;Below, we will first introduce the related core components&#xA;Agent At the design level of the Agent, we provide four basic types of Agents, which allows for the basic role settings of these Agents to meet the interaction and usage of a variety of common scenarios.</description>
    </item>
    <item>
      <title>ChatBot-RoadMap</title>
      <link>/docs/chatbot-roadmap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/chatbot-roadmap/</guid>
      <description>ä¸­æ–‡&amp;nbsp ï½œ &amp;nbspEnglish&amp;nbsp RoadMap Roadmap Overview&#xA;Sandbox Environment âœ… Isolated sandbox environment for code execution âœ… File upload and download âœ… Support for Java execution environment â¬œ Vector Database &amp;amp; Retrieval âœ… Task retrieval âœ… Tool retrieval âœ… Prompt Management âœ… Memory Management âœ… Multi Agent Framework âœ… PRD (Product Requirement Document), system analysis, interface design â¬œ Generate code based on requirement documents, system analysis, and interface design â¬œ Automated testing, automated debugger â¬œ Operations process integration (ToolLearning) â¬œ Fully automated end-to-end process â¬œ Integration with LLM based on fastchat âœ… Integration with Text Embedding based on sentencebert âœ… Improved vector loading speed âœ… Connector âœ… React Mode based on langchain âœ… Tool retrieval completed with langchain âœ… General Capability for Web Crawl â¬œ Technical documentation: Zhihu, CSDN, Alibaba Cloud Developer Forum, Tencent Cloud Developer Forum, etc.</description>
    </item>
    <item>
      <title>CoAgent</title>
      <link>/coagent/coagent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/coagent/</guid>
      <description>ç®€ä»‹ To enhance the performance of large language models (LLMs) in terms of inference accuracy, the industry has seen various innovative approaches to utilizing LLMs. From the earliest Chain of Thought (CoT), Text of Thought (ToT), to Graph of Thought (GoT), these methods have continually expanded the capability boundaries of LLMs. In dealing with complex problems, we can use the ReAct process to select, invoke, and execute tool feedback, achieving multi-round tool usage and multi-step execution.</description>
    </item>
    <item>
      <title>Codefuse-ChatBot Development by Private Knowledge Augmentation</title>
      <link>/docs/codefuse-chatbot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-chatbot/</guid>
      <description>ä¸­æ–‡&amp;nbsp ï½œ &amp;nbspEnglish&amp;nbsp This project is an open-source AI intelligent assistant, specifically designed for the entire lifecycle of software development, covering design, coding, testing, deployment, and operations. Through knowledge retrieval, tool utilization, and sandbox execution, Codefuse-ChatBot can not only answer professional questions you encounter during the development process but also coordinate multiple independent, dispersed platforms through a conversational interface.&#xA;ğŸ“œ Contents ğŸ¤ Introduction ğŸ§­ Technical Route ğŸ¤ Introduction ğŸ’¡ The aim of this project is to construct an AI intelligent assistant for the entire lifecycle of software development, covering design, coding, testing, deployment, and operations, through Retrieval Augmented Generation (RAG), Tool Learning, and sandbox environments.</description>
    </item>
    <item>
      <title>codefuse-devops-eval</title>
      <link>/docs/codefuse-devops-eval/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-devops-eval/</guid>
      <description>Comming soon</description>
    </item>
    <item>
      <title>codefuse-devops-model</title>
      <link>/docs/codefuse-devops-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-devops-model/</guid>
      <description>Comming soon</description>
    </item>
    <item>
      <title>CodeFuse-ModelCache</title>
      <link>/docs/codefuse-modelcache/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-modelcache/</guid>
      <description>CodeFuse-ModelCache CodeFuse-ModelCache</description>
    </item>
    <item>
      <title>CodeFuse-Query</title>
      <link>/docs/codefuse-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/codefuse-query/</guid>
      <description>CodeFuse-Query CodeFuse-Query</description>
    </item>
    <item>
      <title>Connector Agent</title>
      <link>/coagent/connector-agent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/connector-agent/</guid>
      <description>å¿«é€Ÿæ„å»ºä¸€ä¸ªAgent é¦–å…ˆå¢åŠ openaié…ç½®ï¼Œä¹Ÿå¯ä»¥æ˜¯å…¶å®ƒç±»ä¼¼äºopenaiæ¥å£çš„æ¨¡å‹ï¼ˆé€šè¿‡fastchatå¯åŠ¨ï¼‰ from coagent.base_configs.env_config import JUPYTER_WORK_PATH, KB_ROOT_PATH&#xD;from coagent.llm_models.llm_config import EmbedConfig, LLMConfig&#xD;from coagent.connector.configs import AGETN_CONFIGS&#xD;from coagent.connector.agents import BaseAgent&#xD;from coagent.connector.schema import Message, load_role_configs&#xD;os.environ[&amp;#34;API_BASE_URL&amp;#34;] = OPENAI_API_BASE&#xD;os.environ[&amp;#34;OPENAI_API_KEY&amp;#34;] = &amp;#34;sk-xx&amp;#34;&#xD;openai.api_key = &amp;#34;sk-xxx&amp;#34;&#xD;# os.environ[&amp;#34;OPENAI_PROXY&amp;#34;] = &amp;#34;socks5h://127.0.0.1:13659&amp;#34;&#xD;os.environ[&amp;#34;DUCKDUCKGO_PROXY&amp;#34;] = os.environ.get(&amp;#34;DUCKDUCKGO_PROXY&amp;#34;) or &amp;#34;socks5://127.0.0.1:13659&amp;#34; é…ç½®ç›¸å…³ LLM å’Œ Embedding Model # LLM å’Œ Embedding Model é…ç½®&#xD;llm_config = LLMConfig(&#xD;model_name=&amp;#34;gpt-3.5-turbo&amp;#34;, model_device=&amp;#34;cpu&amp;#34;,api_key=os.environ[&amp;#34;OPENAI_API_KEY&amp;#34;], api_base_url=os.environ[&amp;#34;API_BASE_URL&amp;#34;], temperature=0.3&#xD;)&#xD;embed_config = EmbedConfig(&#xD;embed_engine=&amp;#34;model&amp;#34;, embed_model=&amp;#34;text2vec-base-chinese&amp;#34;, embed_model_path=&amp;#34;D://project/gitlab/llm/external/ant_code/Codefuse-chatbot/embedding_models/text2vec-base-chinese&amp;#34;&#xD;) è¿™é‡Œä»å·²æœ‰çš„agenté…ç½®é€‰ä¸€ä¸ªroleæ¥åšç¤ºä¾‹ # ä»å·²æœ‰çš„é…ç½®ä¸­é€‰æ‹©ä¸€ä¸ªconfigï¼Œå…·ä½“å‚æ•°ç»†èŠ‚è§ä¸‹é¢&#xD;role_configs = load_role_configs(AGETN_CONFIGS)&#xD;agent_config = role_configs[&amp;#34;general_planner&amp;#34;]&#xD;# ç”Ÿæˆagentå®ä¾‹&#xD;base_agent = BaseAgent(&#xD;role=agent_config.</description>
    </item>
    <item>
      <title>Connector Chain</title>
      <link>/coagent/connector-chain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/connector-chain/</guid>
      <description>å¿«é€Ÿæ„å»ºä¸€ä¸ª agent chain é¦–å…ˆå¢åŠ openaié…ç½®ï¼Œä¹Ÿå¯ä»¥æ˜¯å…¶å®ƒç±»ä¼¼äºopenaiæ¥å£çš„æ¨¡å‹ï¼ˆé€šè¿‡fastchatå¯åŠ¨ï¼‰ # è®¾ç½®openaiçš„api-key&#xD;import os, sys&#xD;import openai&#xD;import importlib&#xD;os.environ[&amp;#34;API_BASE_URL&amp;#34;] = OPENAI_API_BASE&#xD;os.environ[&amp;#34;OPENAI_API_KEY&amp;#34;] = &amp;#34;sk-xxxx&amp;#34;&#xD;openai.api_key = &amp;#34;sk-xxxx&amp;#34;&#xD;# os.environ[&amp;#34;OPENAI_PROXY&amp;#34;] = &amp;#34;socks5h://127.0.0.1:13659&amp;#34;&#xD;os.environ[&amp;#34;DUCKDUCKGO_PROXY&amp;#34;] = os.environ.get(&amp;#34;DUCKDUCKGO_PROXY&amp;#34;) or &amp;#34;socks5://127.0.0.1:13659&amp;#34; é…ç½®ç›¸å…³ LLM å’Œ Embedding Model # LLM å’Œ Embedding Model é…ç½®&#xD;llm_config = LLMConfig(&#xD;model_name=&amp;#34;gpt-3.5-turbo&amp;#34;, model_device=&amp;#34;cpu&amp;#34;,api_key=os.environ[&amp;#34;OPENAI_API_KEY&amp;#34;], api_base_url=os.environ[&amp;#34;API_BASE_URL&amp;#34;], temperature=0.3&#xD;)&#xD;embed_config = EmbedConfig(&#xD;embed_engine=&amp;#34;model&amp;#34;, embed_model=&amp;#34;text2vec-base-chinese&amp;#34;, embed_model_path=&amp;#34;D://project/gitlab/llm/external/ant_code/Codefuse-chatbot/embedding_models/text2vec-base-chinese&amp;#34;&#xD;) è¿™é‡Œä»å·²æœ‰çš„agenté…ç½®é€‰å¤šä¸ªroleç»„åˆæˆ agent chain from coagent.base_configs.env_config import JUPYTER_WORK_PATH, KB_ROOT_PATH&#xD;from coagent.llm_models.llm_config import EmbedConfig, LLMConfig&#xD;from coagent.</description>
    </item>
    <item>
      <title>Connector Memory</title>
      <link>/coagent/connector-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/connector-memory/</guid>
      <description>Memory Manager ä¸»è¦ç”¨äº chat history çš„ç®¡ç†ï¼Œæš‚æœªå®Œæˆ&#xA;å°†chat historyåœ¨æ•°æ®åº“è¿›è¡Œè¯»å†™ç®¡ç†ï¼ŒåŒ…æ‹¬user inputã€ llm outputã€doc retrievalã€code retrievalã€search retrieval å¯¹ chat history è¿›è¡Œå…³é”®ä¿¡æ¯æ€»ç»“ summary contextï¼Œä½œä¸º prompt context æä¾›æ£€ç´¢åŠŸèƒ½ï¼Œæ£€ç´¢ chat history æˆ–è€… summary context ä¸­ä¸é—®é¢˜ç›¸å…³ä¿¡æ¯ï¼Œè¾…åŠ©é—®ç­” ä½¿ç”¨ç¤ºä¾‹ åˆ›å»º memory manager å®ä¾‹ import os&#xD;import openai&#xD;from coagent.base_configs.env_config import KB_ROOT_PATH&#xD;from coagent.connector.memory_manager import BaseMemoryManager, LocalMemoryManager&#xD;from coagent.llm_models.llm_config import EmbedConfig, LLMConfig&#xD;from coagent.connector.schema import Message&#xD;os.environ[&amp;#34;API_BASE_URL&amp;#34;] = OPENAI_API_BASE&#xD;os.environ[&amp;#34;OPENAI_API_KEY&amp;#34;] = &amp;#34;sk-xx&amp;#34;&#xD;openai.api_key = &amp;#34;sk-xxx&amp;#34;&#xD;# os.environ[&amp;#34;OPENAI_PROXY&amp;#34;] = &amp;#34;socks5h://127.0.0.1:13659&amp;#34;&#xD;os.environ[&amp;#34;DUCKDUCKGO_PROXY&amp;#34;] = os.</description>
    </item>
    <item>
      <title>Connector Phase</title>
      <link>/coagent/connector-phase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/connector-phase/</guid>
      <description>å¿«é€Ÿæ„å»ºä¸€ä¸ª agent phase é¦–å…ˆå¢åŠ openaié…ç½®ï¼Œä¹Ÿå¯ä»¥æ˜¯å…¶å®ƒç±»ä¼¼äºopenaiæ¥å£çš„æ¨¡å‹ï¼ˆé€šè¿‡fastchatå¯åŠ¨ï¼‰ from coagent.base_configs.env_config import JUPYTER_WORK_PATH, KB_ROOT_PATH&#xD;from coagent.llm_models.llm_config import EmbedConfig, LLMConfig&#xD;from coagent.connector.configs import AGETN_CONFIGS&#xD;from coagent.connector.phase import BasePhase&#xD;from coagent.connector.schema import Message, load_role_configs&#xD;os.environ[&amp;#34;API_BASE_URL&amp;#34;] = OPENAI_API_BASE&#xD;os.environ[&amp;#34;OPENAI_API_KEY&amp;#34;] = &amp;#34;sk-xx&amp;#34;&#xD;openai.api_key = &amp;#34;sk-xxx&amp;#34;&#xD;# os.environ[&amp;#34;OPENAI_PROXY&amp;#34;] = &amp;#34;socks5h://127.0.0.1:13659&amp;#34;&#xD;os.environ[&amp;#34;DUCKDUCKGO_PROXY&amp;#34;] = os.environ.get(&amp;#34;DUCKDUCKGO_PROXY&amp;#34;) or &amp;#34;socks5://127.0.0.1:13659&amp;#34; é…ç½®ç›¸å…³ LLM å’Œ Embedding Model # LLM å’Œ Embedding Model é…ç½®&#xD;llm_config = LLMConfig(&#xD;model_name=&amp;#34;gpt-3.5-turbo&amp;#34;, model_device=&amp;#34;cpu&amp;#34;,api_key=os.environ[&amp;#34;OPENAI_API_KEY&amp;#34;], api_base_url=os.environ[&amp;#34;API_BASE_URL&amp;#34;], temperature=0.3&#xD;)&#xD;embed_config = EmbedConfig(&#xD;embed_engine=&amp;#34;model&amp;#34;, embed_model=&amp;#34;text2vec-base-chinese&amp;#34;, embed_model_path=&amp;#34;D://project/gitlab/llm/external/ant_code/Codefuse-chatbot/embedding_models/text2vec-base-chinese&amp;#34;&#xD;) è¿™é‡Œä»å·²æœ‰çš„ phase é…ç½®ä¸­é€‰ä¸€ä¸ª phase æ¥åšç¤ºä¾‹ # log-levelï¼Œprint promptå’Œllm predict&#xD;os.</description>
    </item>
    <item>
      <title>Connector Prompt</title>
      <link>/coagent/connector-prompt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/connector-prompt/</guid>
      <description>Prompt çš„æ ‡å‡†ç»“æ„ åœ¨æ•´ä¸ªPromptçš„æ•´ä¸ªç»“æ„ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å»å®šä¹‰ä¸‰ä¸ªéƒ¨åˆ†&#xA;Agent Profil Input Format Response Output Format #### Agent Profile&#xD;Agent Description ...&#xD;#### Input Format&#xD;**Origin Query:** the initial question or objective that the user wanted to achieve&#xD;**Context:** the current status and history of the tasks to determine if Origin Query has been achieved.&#xD;#### Response Output Format&#xD;**Action Status:** finished or continued&#xD;If it&amp;#39;s &amp;#39;finished&amp;#39;, the context can answer the origin query.&#xD;If it&amp;#39;s &amp;#39;continued&amp;#39;, the context cant answer the origin query.</description>
    </item>
    <item>
      <title>Contribution Guide</title>
      <link>/contribution/contribution-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/contribution/contribution-guide/</guid>
      <description>ä¸­æ–‡&amp;nbsp ï½œ &amp;nbspEnglish&amp;nbsp Thank you for your interest in the Codefuse project. We warmly welcome any suggestions, opinions (including criticisms), comments, and contributions to the Codefuse project.&#xA;Your suggestions, opinions, and comments on Codefuse can be directly submitted through GitHub Issues.&#xA;There are many ways to participate in the Codefuse project and contribute to it: code implementation, test writing, process tool improvement, documentation enhancement, and more. We welcome any contributions and will add you to our list of contributors.</description>
    </item>
    <item>
      <title>Customed Examples</title>
      <link>/coagent/customed-examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/customed-examples/</guid>
      <description>å¦‚ä½•åˆ›å»ºä½ ä¸ªæ€§åŒ–çš„ agent phase åœºæ™¯ ä¸‹é¢é€šè¿‡ autogen çš„ auto_feedback_from_code_execution æ„å»ºè¿‡æ¥ï¼Œæ¥è¯¦ç»†æ¼”ç¤ºå¦‚ä½•è‡ªå®šä¹‰ä¸€ä¸ª agent phase çš„æ„å»º&#xA;è®¾è®¡ä½ çš„promptç»“æ„ import os, sys, requests&#xD;# from configs.model_config import *&#xD;from coagent.connector.phase import BasePhase&#xD;from coagent.connector.chains import BaseChain&#xD;from coagent.connector.schema import Message&#xD;from coagent.connector.configs import AGETN_CONFIGS, CHAIN_CONFIGS, PHASE_CONFIGS&#xD;import importlib&#xD;# update new agent configs&#xD;auto_feedback_from_code_execution_PROMPT = &amp;#34;&amp;#34;&amp;#34;#### Agent Profile&#xD;You are a helpful AI assistant. Solve tasks using your coding and language skills.&#xD;In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.</description>
    </item>
    <item>
      <title>FasterTransformer4CodeFuse</title>
      <link>/docs/fastertransformer4codefuse/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/fastertransformer4codefuse/</guid>
      <description>FasterTransformer4CodeFuse FasterTransformer4CodeFuse</description>
    </item>
    <item>
      <title>Issue Report</title>
      <link>/contribution/issue-report/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/contribution/issue-report/</guid>
      <description>ä¸­æ–‡&amp;nbsp ï½œ &amp;nbspEnglish&amp;nbsp Issue Type Issues can be categorized into three types:&#xA;Bug: Issues where code or execution examples contain bugs or lack dependencies, resulting in incorrect execution. Documentation: Discrepancies in documentation, inconsistencies between documentation content and code, etc. Feature: New functionalities that evolve from the current codebase. Issue Template Issue: Bug Template Checklist before submitting an issue Please confirm that you have checked the document, issues, discussions (GitHub feature), and other publicly available documentation.</description>
    </item>
    <item>
      <title>LLM-Configuration</title>
      <link>/docs/LLM-Configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/LLM-Configuration/</guid>
      <description>ä¸­æ–‡&amp;nbsp ï½œ &amp;nbspEnglish&amp;nbsp Local Privatization/Large Model Interface Access Leveraging open-source LLMs (Large Language Models) and Embedding models, this project enables offline private deployment based on open-source models.&#xA;In addition, the project supports the invocation of OpenAI API.&#xA;Local Privatization Model Access Example of model address configuration, modification of the model_config.py configuration:&#xA;# Recommendation: Use Hugging Face models, preferably the chat models, and avoid using base models, which may not produce correct outputs.</description>
    </item>
    <item>
      <title>MFTCoder</title>
      <link>/docs/mftcoder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/mftcoder/</guid>
      <description>MFTCoder MFTCoder</description>
    </item>
    <item>
      <title>overview</title>
      <link>/docs/en_overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/en_overview/</guid>
      <description>HuggingFace | ModelScope Hello World! This is CodeFuse! CodeFuse aims to develop Code Large Language Models (Code LLMs) to support and enhance full-lifecycle AI native sotware developing, covering crucial stages such as design requirements, coding, testing, building, deployment, operations, and insight analysis.&#xA;We are passionating about creating innovative open-source solutions that empower developers throughout the software development process as shown above. We also encourage engineers and researchers within this community to join us in co-constructing/improving CodeFuse.</description>
    </item>
    <item>
      <title>Prompt Manager</title>
      <link>/coagent/prompt-manager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/prompt-manager/</guid>
      <description>æç¤ºç®¡ç†å™¨ï¼ˆPrompt Managerï¼‰ ç®¡ç†å¤šæ™ºèƒ½ä½“é“¾è·¯ä¸­çš„promptåˆ›å»º&#xA;å¿«é€Ÿé…ç½®ï¼šé‡‡ç”¨é¢„è®¾çš„å¤„ç†å‡½æ•°ï¼Œç”¨æˆ·ä»…éœ€é€šè¿‡å®šä¹‰æ™ºèƒ½ä½“çš„è¾“å…¥è¾“å‡ºå³å¯è½»æ¾é…ç½®ï¼Œå®ç°å¤šæ™ºèƒ½ä½“çš„promptå¿«é€Ÿç»„è£…å’Œé…ç½®ã€‚ è‡ªå®šä¹‰æ”¯æŒï¼šå…è®¸ç”¨æˆ·è‡ªå®šä¹‰promptå†…éƒ¨å„æ¨¡å—çš„å¤„ç†é€»è¾‘ï¼Œä»¥è¾¾åˆ°ä¸ªæ€§åŒ–çš„æ™ºèƒ½ä½“promptå®ç°ã€‚ Prompté¢„è®¾æ¨¡æ¿ç»“æ„ Agent Profileï¼šæ­¤éƒ¨åˆ†æ¶‰åŠåˆ°æ™ºèƒ½ä½“çš„åŸºç¡€æè¿°ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä»£ç†çš„ç±»å‹ã€åŠŸèƒ½å’ŒæŒ‡ä»¤é›†ã€‚ç”¨æˆ·å¯ä»¥åœ¨è¿™é‡Œè®¾ç½®æ™ºèƒ½ä½“çš„åŸºæœ¬å±æ€§ï¼Œç¡®ä¿å…¶è¡Œä¸ºä¸é¢„æœŸç›¸ç¬¦ã€‚ Contextï¼šä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç»™æ™ºèƒ½ä½“åšå‚è€ƒï¼Œå¸®åŠ©æ™ºèƒ½ä½“æ›´å¥½çš„è¿›è¡Œå†³ç­–ã€‚ Tool Informationï¼šæ­¤éƒ¨åˆ†ä¸ºæ™ºèƒ½ä½“æä¾›äº†ä¸€å¥—å¯ç”¨å·¥å…·çš„æ¸…å•ï¼Œæ™ºèƒ½ä½“å¯ä»¥æ ¹æ®å½“å‰çš„åœºæ™¯éœ€æ±‚ä»ä¸­æŒ‘é€‰åˆé€‚çš„å·¥å…·ä»¥è¾…åŠ©å…¶æ‰§è¡Œä»»åŠ¡ã€‚ Reference Documentsï¼šè¿™é‡Œå¯ä»¥åŒ…å«ä»£ç†å‚è€ƒä½¿ç”¨çš„æ–‡æ¡£æˆ–ä»£ç ç‰‡æ®µï¼Œä»¥ä¾¿äºå®ƒåœ¨å¤„ç†è¯·æ±‚æ—¶èƒ½å¤Ÿå‚ç…§ç›¸å…³èµ„æ–™ã€‚ Session Recordsï¼šåœ¨è¿›è¡Œå¤šè½®å¯¹è¯æ—¶ï¼Œæ­¤éƒ¨åˆ†ä¼šè®°å½•ä¹‹å‰çš„äº¤è°ˆå†…å®¹ï¼Œç¡®ä¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨ä¸Šä¸‹æ–‡ä¸­ä¿æŒè¿è´¯æ€§ã€‚ Response Output Formatï¼šç”¨æˆ·å¯ä»¥åœ¨æ­¤è®¾ç½®æ™ºèƒ½ä½“çš„è¾“å‡ºæ ¼å¼ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„å“åº”æ»¡è¶³ç‰¹å®šçš„æ ¼å¼è¦æ±‚ï¼ŒåŒ…æ‹¬ç»“æ„ã€è¯­æ³•ç­‰ã€‚ Responseï¼šåœ¨ä¸æ™ºèƒ½ä½“çš„å¯¹è¯ä¸­ï¼Œå¦‚æœç”¨æˆ·å¸Œæœ›æ™ºèƒ½ä½“ç»§ç»­æŸä¸ªè¯é¢˜æˆ–å†…å®¹ï¼Œå¯ä»¥åœ¨æ­¤æ¨¡å—ä¸­è¾“å…¥ç»­å†™çš„ä¸Šæ–‡ã€‚ä¾‹å¦‚ï¼Œåœ¨è¿ç”¨REACTæ¨¡å¼æ—¶ï¼Œå¯ä»¥åœ¨æ­¤åŒºåŸŸå†…è¯¦ç»†é˜è¿°æ™ºèƒ½ä½“å…ˆå‰çš„è¡Œä¸ºå’Œè§‚å¯Ÿç»“æœï¼Œä»¥ä¾¿äºæ™ºèƒ½ä½“æ„å»ºè¿è´¯çš„åç»­å“åº”ã€‚ Promptè‡ªå®šä¹‰é…ç½® Promptæ¨¡å—å‚æ•° field_nameï¼šå”¯ä¸€çš„å­—æ®µåç§°æ ‡è¯†ï¼Œå¿…é¡»æä¾›ã€‚ functionï¼šæŒ‡å®šå¦‚ä½•å¤„ç†è¾“å…¥æ•°æ®çš„å‡½æ•°ï¼Œå¿…é¡»æä¾›ã€‚ titleï¼šå®šä¹‰æ¨¡å—çš„æ ‡é¢˜ã€‚è‹¥æœªæä¾›ï¼Œå°†è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªæ ‡é¢˜ï¼Œè¯¥æ ‡é¢˜é€šè¿‡æŠŠå­—æ®µåç§°ä¸­çš„ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼å¹¶å°†æ¯ä¸ªå•è¯çš„é¦–å­—æ¯å¤§å†™æ¥æ„å»ºã€‚ descriptionï¼šæä¾›æ¨¡å—çš„ç®€è¦æè¿°ï¼Œä½äºæ¨¡å—æœ€ä¸Šæ–¹ï¼ˆæ ‡é¢˜ä¸‹æ–¹ï¼‰ã€‚é»˜è®¤ä¸ºç©ºï¼Œå¯é€‰å¡«ã€‚ is_contextï¼šæ ‡è¯†è¯¥å­—æ®µæ˜¯å¦å±äºä¸Šä¸‹æ–‡æ¨¡å—çš„ä¸€éƒ¨åˆ†ã€‚é»˜è®¤ä¸ºTrueï¼Œæ„å‘³ç€é™¤éæ˜¾å¼æŒ‡å®šä¸ºFalseï¼Œå¦åˆ™éƒ½è¢«è§†ä¸ºä¸Šä¸‹æ–‡çš„ä¸€éƒ¨åˆ†ã€‚ omit_if_emptyï¼šè®¾å®šå½“æ¨¡å—å†…å®¹ä¸ºç©ºæ—¶ï¼Œæ˜¯å¦åœ¨promptä¸­çœç•¥è¯¥æ¨¡å—ï¼Œå³ä¸æ˜¾ç¤ºç›¸åº”çš„æ¨¡æ¿æ ‡é¢˜å’Œå†…å®¹ã€‚é»˜è®¤ä¸ºFalseï¼Œæ„å‘³ç€å³ä½¿å†…å®¹ä¸ºç©ºä¹Ÿä¼šæ˜¾ç¤ºæ ‡é¢˜ã€‚å¦‚æœå¸Œæœ›å†…å®¹ä¸ºç©ºæ—¶çœç•¥æ¨¡å—ï¼Œéœ€æ˜¾å¼è®¾ç½®ä¸ºTrueã€‚ Prompté…ç½®ç¤ºä¾‹ Prompté…ç½®ç”±ä¸€ç³»åˆ—å®šä¹‰promptæ¨¡å—çš„å­—å…¸ç»„æˆï¼Œè¿™äº›æ¨¡å—å°†æ ¹æ®æŒ‡å®šçš„å‚æ•°å’ŒåŠŸèƒ½æ¥å¤„ç†è¾“å…¥æ•°æ®å¹¶ç»„ç»‡æˆä¸€ä¸ªå®Œæ•´çš„promptã€‚&#xA;åœ¨é…ç½®ä¸­ï¼Œæ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€ä¸ªæ¨¡å—ï¼Œå…¶ä¸­åŒ…å«ç›¸å…³çš„å‚æ•°å¦‚ field_name, function_name, is_context, title, description, å’Œ omit_if_emptyï¼Œç”¨ä»¥æ§åˆ¶æ¨¡å—çš„è¡Œä¸ºå’Œå‘ˆç°æ–¹å¼ã€‚&#xA;context_placeholder å­—æ®µç”¨äºæ ‡è¯†ä¸Šä¸‹æ–‡æ¨¡æ¿çš„ä½ç½®ï¼Œå…è®¸åœ¨promptä¸­æ’å…¥åŠ¨æ€å†…å®¹ã€‚&#xA;[ {&amp;#34;field_name&amp;#34;: &amp;#39;agent_profile&amp;#39;, &amp;#34;function_name&amp;#34;: &amp;#39;handle_agent_profile&amp;#39;, &amp;#34;is_context&amp;#34;: False}, {&amp;#34;field_name&amp;#34;: &amp;#39;context_placeholder&amp;#39;, &amp;#34;function_name&amp;#34;: &amp;#39;&amp;#39;, &amp;#34;is_context&amp;#34;: True}, {&amp;#34;field_name&amp;#34;: &amp;#39;tool_information&amp;#39;,&amp;#34;function_name&amp;#34;: &amp;#39;handle_tool_data&amp;#39;, &amp;#34;is_context&amp;#34;: True}, {&amp;#34;field_name&amp;#34;: &amp;#39;reference_documents&amp;#39;, &amp;#34;function_name&amp;#34;: &amp;#39;handle_doc_info&amp;#39;}, {&amp;#34;field_name&amp;#34;: &amp;#39;session_records&amp;#39;, &amp;#34;function_name&amp;#34;: &amp;#39;handle_session_records&amp;#39;}, {&amp;#34;field_name&amp;#34;: &amp;#39;task_records&amp;#39;, &amp;#34;function_name&amp;#34;: &amp;#39;handle_task_records&amp;#39;}, {&amp;#34;field_name&amp;#34;: &amp;#39;output_format&amp;#39;, &amp;#34;function_name&amp;#34;: &amp;#39;handle_output_format&amp;#39;, &amp;#39;title&amp;#39;: &amp;#39;Response Output Format&amp;#39;, &amp;#34;is_context&amp;#34;: False}, {&amp;#34;field_name&amp;#34;: &amp;#39;response&amp;#39;, &amp;#34;function_name&amp;#34;: &amp;#39;handle_response&amp;#39;, &amp;#34;title&amp;#34;=&amp;#34;begin!</description>
    </item>
    <item>
      <title>Pull Request</title>
      <link>/contribution/pull-request/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/contribution/pull-request/</guid>
      <description>ä¸­æ–‡&amp;nbsp ï½œ &amp;nbspEnglish&amp;nbsp Contribution Pre-Checklist First, confirm whether you have checked the document, issue, discussion (GitHub features), or other publicly available documentation. Find the GitHub issue you want to address. If none exists, create an issue or draft PR and ask a Maintainer for a check Check for related, similar, or duplicate pull requests Create a draft pull request Complete the PR template for the description Link any GitHub issue(s) that are resolved by your PR Description A description of the PR should be articulated in concise language, highlighting the work completed by the PR.</description>
    </item>
    <item>
      <title>Quick Start</title>
      <link>/coagent/quick-start/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/coagent/quick-start/</guid>
      <description>Quick Start First, set up the LLM configuration import os, sys&#xD;import openai&#xD;# llm config&#xD;os.environ[&amp;#34;API_BASE_URL&amp;#34;] = OPENAI_API_BASE&#xD;os.environ[&amp;#34;OPENAI_API_KEY&amp;#34;] = &amp;#34;sk-xxx&amp;#34;&#xD;openai.api_key = &amp;#34;sk-xxx&amp;#34;&#xD;# os.environ[&amp;#34;OPENAI_PROXY&amp;#34;] = &amp;#34;socks5h://127.0.0.1:13659&amp;#34; Next, configure the LLM settings and vector model from coagent.llm_models.llm_config import EmbedConfig, LLMConfig&#xD;llm_config = LLMConfig(&#xD;model_name=&amp;#34;gpt-3.5-turbo&amp;#34;, model_device=&amp;#34;cpu&amp;#34;,api_key=os.environ[&amp;#34;OPENAI_API_KEY&amp;#34;], api_base_url=os.environ[&amp;#34;API_BASE_URL&amp;#34;], temperature=0.3&#xD;)&#xD;embed_config = EmbedConfig(&#xD;embed_engine=&amp;#34;model&amp;#34;, embed_model=&amp;#34;text2vec-base-chinese&amp;#34;, embed_model_path=&amp;#34;D://project/gitlab/llm/external/ant_code/Codefuse-chatbot/embedding_models/text2vec-base-chinese&amp;#34;&#xD;) Finally, choose a pre-existing scenario to execute from coagent.tools import toLangchainTools, TOOL_DICT, TOOL_SETS&#xD;from coagent.</description>
    </item>
    <item>
      <title>QuickStart</title>
      <link>/docs/quickstart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/quickstart/</guid>
      <description>ä¸­æ–‡&amp;nbsp ï½œ &amp;nbspEnglish&amp;nbsp ğŸš€ Quick Start To deploy private models, please install the NVIDIA driver by yourself. This project has been tested on Python 3.9.18 and CUDA 11.7 environments, as well as on Windows and macOS systems with x86 architecture. For Docker installation, private LLM access, and related startup issues, see: Start-detail&amp;hellip;&#xA;Preparation of Python environment It is recommended to use conda to manage the python environment (optional) # Prepare conda environment conda create --name Codefusegpt python=3.</description>
    </item>
    <item>
      <title>Start-Detail</title>
      <link>/docs/chatbot/start-detail/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/chatbot/start-detail/</guid>
      <description>ä¸­æ–‡&amp;nbsp ï½œ &amp;nbspEnglish&amp;nbsp If you need to deploy a privatized model, please install the NVIDIA driver yourself.&#xA;Preparation of Python environment It is recommended to use conda to manage the python environment (optional) # Prepare conda environment conda create --name Codefusegpt python=3.9 conda activate Codefusegpt Install related dependencies cd Codefuse-ChatBot pip install -r requirements.txt Sandbox Environment Preparation Windows Docker installation: Docker Desktop for Windows supports 64-bit versions of Windows 10 Pro with Hyper-V enabled (Hyper-V is not required for versions v1903 and above), or 64-bit versions of Windows 10 Home v1903 and above.</description>
    </item>
    <item>
      <title>Test-Agent</title>
      <link>/docs/test-agent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/docs/test-agent/</guid>
      <description>Test-Agent Test-Agent</description>
    </item>
  </channel>
</rss>
